{
  "permissions": {
    "allow": [
      "Bash(npm test:*)",
      "Bash(npm run test:unit:*)",
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "Bash(git push:*)",
      "Bash(gh pr create --title \"Fix exercise resolver ranking with token-based scoring\" --body \"$(cat <<''EOF''\n## Summary\n\nFixes the exercise resolver to rank search results using token-based scoring instead of relying solely on PostgreSQL''s full-text search ranking. This solves the issue where \"Bench Press\" would incorrectly match \"Close-Grip Barbell Bench Press\" instead of \"Barbell Bench Press\".\n\n### Key Changes\n\n- **Added `scoreByToken()` method**: Computes similarity score based on overlapping tokens with penalties for extra distractor words\n- **Added `rankByToken()` method**: Re-ranks search results using the token-based scores  \n- **Updated `aiExerciseResolver`**: Fetches 50 results (wider net) and re-ranks them using token scoring for better matches\n- **Comprehensive tests**: Added 14 new test cases covering the scoring and ranking logic\n\n### Scoring Formula\n\n```\nscore = (exact token matches Ã— 1.0) - (extra distractor tokens Ã— 0.1)\n```\n\n### Example\n\nQuery: \"Bench Press\"\n- âœ… \"Barbell Bench Press\" scores 1.9 (2 matches - 1 extra = 2.0 - 0.1)\n- âŒ \"Close-Grip Barbell Bench Press\" scores 1.7 (2 matches - 3 extra = 2.0 - 0.3)\n\nNow \"Barbell Bench Press\" correctly ranks higher!\n\n### Design Decision\n\nThis approach keeps existing search behavior unchanged (fast, database-level ranking) while improving accuracy only where it matters most: the AI exercise resolver where we need the best possible match.\n\n## Test Plan\n\n- [x] All existing unit tests pass (139 tests)\n- [x] 14 new tests for `scoreByToken` and `rankByToken` pass\n- [x] TypeScript type check passes\n- [x] Verified scoring logic with multiple test cases including edge cases\n\nFixes #80\n\nðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\nEOF\n)\")"
    ],
    "deny": [],
    "ask": []
  }
}
